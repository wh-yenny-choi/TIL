# 머신러닝 (Machine Learning) 개요

머신러닝 = 기계 학습

인공지능의 한 분야로, 기계가 학습할 수 있는 알고리즘과 기술을 개발하는 분야이다.

기계가 학습하기 위해서는 반드시 학습 할 수 있는 **데이터**가 필요하다.

머신러닝은 다양한 분야에서 적극적으로 활용 중 이다.



## 인공지능(AI)의 역사

### 인공지능의 탄생(1943-1956)

- 인공두뇌학과 초기 신경 네트워크

- 튜링 테스트
- 게임 인공지능
- 상징 추론과 논리 이론
- 다트머스 컨퍼런스 1956년 : AI의 탄생

### 황금기(1956~1974년)

- 작업들
- 탐색 추리
- 자연어 처리
- 마이크로월드
- 낙관론
- 자금

### AI의 첫번째 암흑기(1974-1980)

- 문제 
  - 컴퓨터 능력의 한계
  - 폭발적인 조합 수와 비용이성
  - 상징적 지식과 추론
  - 모라벡의 패러독스
  - 프레임 문제, 자격 문제
- 자금 지원의 중단
- 캠퍼스 전역의 비판들
- 퍼센트론과 연결망의 어두운 시대
- 깔끔이 : 논리, 프롤로그와 전문가 시스템
- 지저분이 : 프레임과 스크립트

### Boom 1980-1987

- 전문가 시스템의 발전
- 지식 혁명
- 돈은 되돌아온다 : 5세대 프로젝트
- 신경망 이론의 복귀

### AI의 두번째 암흑기 1987-1993

- 인공지능의 겨울
- 몸통을 갖는 것의 중요성

### AI 2018-현재

- 성공 사례와 무어의 법칙
- 지능형 에이전트
- 깔끔함의 승리



## 머시러닝의 주요 알고리즘

### 확률적 모델링





## 알고리즘 선택 시 고려 사항

알고리즘을 선택할 때에는 언제나 **정확성, 학습시간, 사용 편의성** 을 고려해야 합니다. 많은 경우 정확성을 최우선으로 두는 반면에 초급자는 가장 잘 알고 있는 알고리즘에 초점을 맞추는 경향이 있습니다.

데이터 세트가 제공됐을 때, ‘어떤 결과가 나올 것인지에 상관없이 어떻게 결과를 얻을것인가’를 가장 먼저 고려해야 합니다. 일부 결과를 얻었고 데이터에 익숙해진 후라면 정교한 알고리즘을 사용하는 데 시간을 더 많이 할애해야 합니다.



## 머시러닝과 인공지능(AI)

![21-1](https://hyeonjiwon.github.io/assets/img/21-1.png)

### 인공지능 (Artifical Intelligence)

인공지능은 인간의 지능이 갖고 있는 기능을 갖춘 컴퓨터 시스템이며, 인간의 지능을 기계 등에 인공적으로 시연(구현)한 가장 큰 범주에 해당합니다. 일반적으로 범용 컴퓨터에 적용한다고 가정합니다.

### 머신러닝 (Machine Learning)

기계 학습 또는 머신 러닝은 인공지능의 한 분야로, 컴퓨터가 학습할 수 있도록 하는 알고리즘과 기술을 개발하는 분야를 말합니다.

### 딥러닝 (Deep Learning)

심층 학습 또는 딥 러닝은 여러 비선형 변환기법의 조합을 통해 높은 수준의 추상화를 시도하는 기계 학습 알고리즘의 집합으로 정의 됩니다. 큰 틀에서 사람의 사고방식을 컴퓨터에게 가르치는 기계학습의 한 분야라고 이야기할 수 있습니다. 딥 러닝은 특징 추출부터 패턴까지 모든 과정을 사람의 개입 없이 심층인공신경망을 토대로 학습방식을 구현하는 기술입니다.

![21-2](https://hyeonjiwon.github.io/assets/img/21-2.png)

- 머신러닝은 인간이 데이터에 대한 결과 값을 미리 알려주어야 하고 목표치에 가까운 결과 값의 특징을 미리 정의해야 합니다.
- 반면에 딥러닝은 인간의 신경망인 뉴런의 작동 원리를 모방한 인공 신경망을 이용하여 복잡하고 방대한 데이터로부터 결과값을 추출하는 원리로 작동합니다.



## 정형 데이터 ↔ 비정형 데이터

- 정형 : 형식이 정해져 있음

- 비정형 : 형식이 정해져 있지 않음



## 머신러닝과 전통적 방식과의 차이

- 전통적 방법의 경우 사소한 문제가 아닌 경우 규칙이 점점 길고 복잡해져 유지보수가 매우 어려움

- 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 경우, 머신러닝 모델 코드를 간단하게 만들 수 있음

- 전통적인 방식으로 해결할 수 없는 복잡한 문제를 머신러닝으로 해결



## 머리신러닝의 장점

- 유동적인 환경 : 새로운 데이터의 적응이 가능



## 어플리케이션 사례

- 머신러닝을 활용해 다양한 분야에 적용
- 이미지 분류 작업
- 시멘틱 분할 작업
- 텍스트 분류 (자연어 처리)
  - 자동으로 뉴스 기사 분류
  - 토론 포럼에서 부정적인 코멘트를 자동으로 구분
- 텍스트 요약
  - 긴 문서를 자동으로 요약
- 자연어 이해 : 챗봇
- 회사의 내년도 수익 예측 : 회귀분석
- 음성 인식
- 이상치 탐지 : 신용 카드 부정 거래 감지
- 군집 작업
- 데이터 시각화
- 추천 시스템
- 강화 학습 : 지능형 게임 봇 만들기

## 1️⃣정리 

다양한 기반의 알고리즘이 다양한 분야에서 적용되어왔고 현재에도 활용

딥러닝에서도 접목된 어플리케이션도 발전되고 있다

머신러닝과 전통적 방법



## 머신러닝의 종류

감독 하에 훈련하는가?

- 지도 학습
- 비지도 학습
- 준지도 학습
- 강화 학습
- 전이 학습

실시간으로 점진적인 학습을 하는지?

- 온라인 학습
  - 많은 양을 데이터를 부분으로 나눔
  - 개별적 또는 소그룹으로 데이터를 순차적으로 공급하여 점진적으로 훈련
- 배치 학습
  - 시스템이 점진적으로 학습할 수 없음
  - 모든 데이터를 사용해 학습
  - 오프라인으로 수행(많은 수행시간)

데이터 비교 vs 모델 기반인지?

- 인스턴스 기반 학습
  - 사례 기반
  - 데이터 끼리의 비교
- 모델 기반 학습
  - 분류

## 기계 학습 기법

![21-3](https://hyeonjiwon.github.io/assets/img/21-3.png)

![2.10-1](https://hyeonjiwon.github.io/assets/img/2.10-1.png)

### 지도 학습 / 감독 학습 

Task Driven (Regression / Classification)

레이블 또는 구조로 데이터 세트의 주소를 지정하는 데이터는 교사와 같은 역할을 하며 머신을 ‘학습’시켜 예측 또는 의사 결정을 내리는 머신의 능력을 강화합니다.

학습 데이터에 입력값(특성)에 대한 출력값(레이블)이 함께 제시

"모델"을 사용하여 새로운 입력값에 대한 예측 수행

출력값이 수치값

- 알고리즘
  - <u>K-최근접이웃 (KNN)</u>
  - <u>선형 회귀</u>
  - <u>로지스틱 회귀</u> 
    - Target변수/레이블/y/output/종속변수 - 범주형 
    - 독립변수/x/input/특징(feature) 여러개 - 다중회귀
    - 독립변수가 한개 - 단순 회귀
  - 서포트 벡터 머신
  - <u>의사결정트리</u>
  - <u>랜덤 포레스트</u>
  - 신경망
    - 딥러닝 (DS쪽)
-  Target변수 = 레이블 = Y = output = 종속변수 
- 특징(Feature) = X = input = 독립 변수 

### 비지도 학습 / 자율 학습

Data Driven (Clustering / 차원 축소)

레이블이나 구조 없이 데이터 세트에 주소를 지정하고 데이터를 클러스터로 그룹화하여 패턴과 관계를 찾아냅니다.

학습 데이터에 레이블이 지정되거나 분류되지 않은 테스트 데이터에서 학습

알고리즘은 학습 데이터의 특징만을 활용하여 목표한 결과를 산출

적절한 군집을 찾거나, 변수의 복잡성을 낮추기 위한 차원 축소 등

GAN등과 같은 새로운 기법이 등장하고 있음

- 알고리즘
  - <u>군집 분석 (Clustering)</u>
    - K-평균
    - 계층적 군집 분석
    - DBSCAN
  - 시각화와 차원 축소
    - <u>주성분 분석(PCA)</u>
    - 커널 PCA
    - 지역적 선형 임베딩 (LLE)
    - t-SNE
  - 이상치 탐색
    - 가우스 분포를 이용한 이상치 탐색
    - 이상치 탐색 방법 : 주어진 데이터들의 분포의 모양을 봐야함
      - 자연적인 분포의 모양 : 정규 분포 (가우스 분포) ⇒ 좌우 대칭, 밀도의 크기 비교
      - 비대칭 분포 ⇒이상치가 있다
      - 이상치 제거해야하는 필수적인 것은 아님. 선택해야 함
  - 연관 규칙
    - Apriori
    - Eclat

### 준지도 학습

모든 데이터에 항상 레이블을 달아 줄 수 있는 것이 아닌 현실을 고려한 접근법

지도와 비지도 알고리즘 조합

- 알고리즘
  - 심층신뢰신경망(DBN)
  - 제한된 볼츠만 기계(RBM)

### 강화 학습

Algorithm learns from mistakes

인간 교환원을 대신하여, 사람 또는 사물을 대신한 컴퓨터 프로그램인 에이전트가 피드백 루프에 따라 결과를 판단하는 데 도움을 줍니다.

Agent인 환경을 관찰하고 행동을 실행하고 그 결과 보상을 받음

행동심리학에서 영향을 받음

- 알고리즘
  - SARSA
  - Q-Learning

### 전이학습(Transfer Learning)

특정 분야에서 학습된 신경망의 일부 능력을 유사하거나 전혀 새로운 분야에서 사용되는 신경망의 학습에 이용하는 것을 의미

 학습 데이터의 수가 적을때도 효과적이며, 학습 속도도 빠르다



## 머신러닝 워크플로우(Workflow)

lterate(1 ~ 6단계 반복)

1. collect data : 유용한 데이터를 최대한 많이 수집
2. prepare data
3. split data
   1. test set
   2. training set
   3. validation set (검증 데이터 셋)
4. train model
5. test and validate model
6. deploy model : 모델의 의사결정 시스템에 탑재 / 적용

```
1. Collect data  : 유용한 데이터를 최대한 많이 확보하고 하나의 데이터 세트로 통합
2. Prepare data  : 결측값, 이상값, 기타 데이터 문제를 적절하게 처리하여 사용 가능한 상태로 준비
3. Split data :  데이터 세트를 학습용과 평가용 세트로 분리
4. Train a model :  이력 데이터의 일부를 활용하여 알고리즘이 데이터 내의 패턴을 잘 찾아 주는지 확인
5. Test and validate a model :  학습 후 모델의 성능을 평가용 데이터 세트로 확인하여 예측 성능을 파악
6. Deploy a model :  모델을 의사결정 시스템에 탑재 / 적용
7. Iterate :  새로운 데이터를 확보하고 점진적으로 모델을 개선
```

- 파생변수 : 주어진 데이터로 새롭게 만들어지는 변수

- 하이퍼 파라메터 조절, 성능을 높이기 위해 검증 데이터 셋, 트레이닝 셋 반복



## 머신러닝 프로젝트 사례 : OECD 행복지수

예시

- 돈이 사람들을 행복하게 하는가?
  - OECD 웹사이트 : Better Life Index

- IMF 웹사이트
  - 1인당 GDP 

데이터 변수의 특성에 따라 시각화 방식을 바꿔야 함

📁lifesat



## 머신러닝 주요 이슈

머신러닝의 주요 작업 : 학습 알고리즘을 선택해서 데이터에 훈련시키는 것

- 나쁜 데이터
  - 충분하지 않은 양의 데이터
  - 대표성이 없는 데이터
    - 왜곡된 데이터, 치우져진 데이터
  - 낮은 품질의 데이터 
    - 오류, 잡음, 이상치, 중복
  - 연관성이 적은 특성(변수)
    - 데이터 분석 자체가 어려움
- 나쁜 알고리즘
  - 훈련 데이터 과대적합
  - 훈련 데이터 과소적합

![image-20210721105633318](머신러닝01 기계학습(ML)개요.assets/image-20210721105633318.png)

- 파랑색 
  - 새로운 데이터(-7위치)가 들어왔을때 오차값이 더 커짐
  - 실제 오차값 : -7 ~ 13까지 (20)
  - 선형에서 보이는 오차값 : -12 ~ -7 (5)

### 테스트와 검증

모델이 새로운 사례에 잘 일반화 될 수 있는가?



## 머신러닝에서 주용되는 주요 패키지

머신러닝 패키지

- 사이킷런 (Scikit-Learn)

배열 / 선형대수 / 통계 패키지

- NumPy
- SciPy

데이터 핸들링

- Pandas

시각화

- Matplotlib
- seaborn

딥러닝

- 텐서플로 (Tensorflow)

- 케라스 (Keras)



### 📌질문 

Q . 산점도의 목적은 두 변수가 수치인 변수. 그렇다면 범주형 변수에는 적용이 안되나요?

A. 범주형간에 두 변수 관계성을 나타내려면 변수의 특성에 따라 달라짐

​	만약, x축이 나이 - y축이 폐암 유무라면, 분포는 볼 수는 있다.

산점도 : 직교 좌표계(도표)를 이용해 좌표상의 점(點)들을 표시함으로써 두 개 변수 간의 관계를 나타내는 그래프 방법

![QC 7도구) 산점도 (Scatter Diagram) : 네이버 블로그](https://mblogthumb-phinf.pstatic.net/MjAxODEyMDZfMTAg/MDAxNTQ0MDYyNTE4NDc4.e_fbzuZSOF6bYE87YGzLTwDuBUEFY1tSjmFL0U2dECIg.aAXOwOYaI79cJT1ziFs_yaP0wyu4TTGHUHl3n_do35kg.PNG.kvmcert/image.png?type=w800)

![고객센터 customer center. 월~금 : 09:00~17:00, 상담 입금계좌안내. 우리은행, 예금주(에스에스에이씨스탯),  계좌번호 요청하신후 문자메세지를 보내 주시면 좀더 빨리 처리됩니다. (010-3920-3596) home 고객센터 &gt; BLOG  공지사항. 우리회사의 새로운 정보와 ...](http://www.ssacstat.com/base/component/board/board_12/u_image/370/20160319074949_1104132722.jpg)



Q2. 강사님 그러면 
산점도 그려서 선형도 보이는지 보고 선형or다른방법(?)으로 한다고 말씀하시면서 
선형은 수치만 가능한가에 대해서 물어보실 때.. 그런 거 같은데.. 주춤했어요.. 
혹시 나이랑 폐암으로 할 경우에는 선형이 된다는 말씀인걸까요?
막대그래프로 표현을 해야 하지 않을까 싶긴 한데요..

A. 산점도를 그릴 순 있지만(=시각화는 가능), 선형성을 나타낼 수 있는 것은 아니다.

​	x축 , y축 수치라면 선형성은 불가능



## 2️⃣정리

머시러닝 개념 복습





## 데이터 리뷰

![image-20210721111827438](머신러닝01 기계학습(ML)개요.assets/image-20210721111827438.png)

- 수치형 : 순서에는 의미가 있음
  - 이산형, 연속형  

![image-20210721112052436](머신러닝01 기계학습(ML)개요.assets/image-20210721112052436.png)

- 수치형 : 순서에는 의미가 있음
  - 등간형, 비율형

![image-20210721112341025](머신러닝01 기계학습(ML)개요.assets/image-20210721112341025.png)

- 변수 = 데이터의 특성
- attribute ⇒ 정형화된 데이터



## 실습1. 마켓과 머신러닝

### 학습 목표  

"변수를 어떻게 보는가?" 를 파악할 수 있다.

### 학습 내용

특성은 데이터를 표현하는 하나의 성질

도미의 길이, 무게는 도미의 특징을 나타내는 특성(feature)라고 함

- 통계학에서는 변수라고 부름

비선형 관계 ⇒ 상관관계는 0



### KNN 알고리즘 소개

테스트 데이터와 K개 훈련데이터의 y값들을 비교

분류와 회귀 모두 활용

- 분류 : K개 최근접 이웃들의 class들 중 다수 결과로 class 예측
  - Label
  - k=3에서 🟣가 2개 🟡가 1개로 ⭐은 ClassB🟣
- 회귀 : K개 최근접 이웃들이 가지고 있는 값의 평균을 결과값으로 예측

![image-20210721131219586](머신러닝01 기계학습(ML)개요.assets/image-20210721131219586.png)

- 위 그림은 train 데이터 세트
- 자료의 평균 벡터 

비모수 방식이며 instance-based알고리즘

train과 test 세트로 데이터를 분리하지만 실제로 train은 존재하지 않는 게으름 알고리즘 

- 학습 데이터 셋 (train)
- 테스트 데이터 셋 (test)

구체적인 데이터를 가지고 예측을 요청할 때, K개 가장 가까운 사례를 train data set에서 찾아 해당하는 데이터의 y값을 기반으로 예측 결과를 제시

K 값 : 동점을 막기 위해 대개 홀수로 정함

- K가 작으면, 이상치 등 노이즈에 민감하게 반응하여 과대적합
  - 과대적합 ⇒ 성능이 떨어짐
  - k = 1인 경우 가장 가까운 이웃과 같은 클래스가 할당됨
- K가 크면, 자료의 패턴을 파악할 수 없어 과소적합
  - k = n인 경우 전체 평균의 개념

- 적절한 k를 찾아 분류

'가깝다'는 판단 기준 : 거리 (맨하탄 거리, 유클리디안 거리, 민코위스키 거리 등)

![image-20210721132105042](머신러닝01 기계학습(ML)개요.assets/image-20210721132105042.png)

- 거리의 개념



### 정확도 (accurancy)

- 정확한 답을 몇개 맞추었는지를 백분율로 나타낸 값
- 정확히 맞힌 개수 / 전체 데이터 수



## 실습1. 생선분류2 (Data Split)

앞의 예에서 훈련데이터에서 도미를 100% 완벽하게 분류함

- 문제점 : 정답을 미리 알려주고 시험보는 것과 같음

훈련한 데이터와 평가에 사용된 데이터가 달라야 함



### Data Split과 모델 검증

층을 나누어 데이터를 분할

- 언제
  - "충분히 큰" 데이터 세트를 가용할 때
  - "충분히 큰" 데이터가 없을 때에는 교차 확인 고려
- 왜
  - 학습에 사용되지 않은 데이터를 사용하여 예측을 수행함으로써 모델의 일반적인 성능에 대한 적절한 예측을 함
- 어떻게
  - 홀드-아웃 (Hold-out)
  - 교차검증 (Cross Validation, CV)
  - 필요에 따라 Stratified Sampling



### 홀드-아웃 방식

- 데이터를 두 개 세트로 나누어 각각 Train과 Test세트로 사용
- Train과 Test의 비율을 7:3 ~ 9:1로 널리 사용하나, 알고리즘의 특성 및 상황에 따라 적절한 비율을 사용
- Train - Vaildation -Test로 나누기도 함

![image-20210721134808855](머신러닝01 기계학습(ML)개요.assets/image-20210721134808855.png)



### 데이터 섞기

![image-20210721140923370](머신러닝01 기계학습(ML)개요.assets/image-20210721140923370.png)



## 실습1. 생선분류3 (Data전처리)

train_test_split (매개 변수들)

- *array : feature dataset, label dataset
- test_size = None
- train_size = None
- shuffle = None
- stratity = None
- random_state = None

