# 분류성능평가지표

기계학습에서 모델이나 패턴이 평가해야하는 요소와 그것을 수치화한 지표들, 관련개념

어느 모델이든간 발전을 위한 feedback은 현재 모델의 performance를 올바르게 평가하는 것에서부터 시작한다.



## 모델의 분류와 정답

모델을 평가하는 요소는 결국, 모델이 내놓은 답과 실제 정답의 관계로써 정의를 내릴 수 있습니다. 정답이 True와 False로 나누어져있고, 분류 모델 또한 True False의 답을 내놓습니다. 그렇게 하면, 아래와 같이 2x2 matrix로 case를 나누어볼 수 있겠네요.



### ![img](https://t1.daumcdn.net/cfile/tistory/99DC064C5BE056CE10)

**<Fig1. Confusion matrix>**

- True Positive(TP) : 실제 True인 정답을 True라고 예측 (정답)
- False Positive(FP) : 실제 False인 정답을 True라고 예측 (오답)
- False Negative(FN) : 실제 True인 정답을 False라고 예측 (오답)
- True Negative(TN) : 실제 False인 정답을 False라고 예측 (정답)



### Precision (정밀도)

모델이 **True**라고 분류한 것 중에 **실제 True인 비율**

![img](https://t1.daumcdn.net/cfile/tistory/99F66B345BE0596109)

Positive 정답률, PPV(Positive Predictive Value)라고도 불린다.

### Accuracy (정확도)

모델이 **True**라고 분류한 것 중에 **실제 True**라고 예측한 경우와 **False**라고 분류한 것 중에 **실제 False**라고 예측한 경우는 모두 옳은 경우이다.

![img](https://t1.daumcdn.net/cfile/tistory/99745F3F5BE0613D1A)

정확도는 가장 직관적으로 모델을 성능을 나타낼 수 있는 평가지표이다.

### Recall (재현율)

실제 **True**인 것 중에서 모델이 **True**라고 예측한 것의 비율

![img](https://t1.daumcdn.net/cfile/tistory/997188435BE05B0628)