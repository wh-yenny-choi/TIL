# SPARK

## SPARK Vs. Hadoop MapReduce

ìŠ¤íŒŒí¬ : ë©”ëª¨ë¦¬ ê¸°ë°˜ ë¶„ì„ í”Œë«í¼

í•˜ë‘¡ : ë””ìŠ¤í¬ê¸°ë°˜ ë¶„ì„ í”Œë«í¼

|             | SPARK                                                 | HadoopMapReduce           |
| ----------- | ----------------------------------------------------- | ------------------------- |
| ì†ë„        | 100 X                                                 | ë¹ ë¦„                      |
| ì²˜ë¦¬ë°©ì‹    | ì‹¤ì‹œê°„ í”„ë¡œì„¸ì‹±                                       | ë°°ì¹˜ í”„ë¡œì„¸ì‹±             |
| ë°ì´í„° ì €ì¥ | ë©”ëª¨ë¦¬ ì €ì¥ ë°©ì‹                                      | ë””ìŠ¤í¬ ì €ì¥ ë°©ì‹          |
| êµ¬í˜„ ì–¸ì–´   | Scala                                                 | Java                      |
| íŠ¹ì§•        | HDfS + MapReduce ì²˜ë¦¬ ì—”ì§„                            | ì „í†µì ì¸ ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ë°©ì‹ |
| ë‹¨ì         | OLTPë³´ë‹¤ëŠ” OLAP ì²˜ë¦¬ íš¨ìœ¨ì , ë©”ëª¨ë¦¬ ë¶„ì‚°ìœ¼ë¡œ overhead | Disk overhead             |

- OLTP = real time batch program
- OLAP



## SPARKì˜ íƒ„ìƒ ë°°ê²½

1. ê¸°ì¡´ì˜ ë¹…ë°ì´í„° ì‹œìŠ¤í…œì˜ ì„±ëŠ¥
2. ê°œë°œì˜ ì–´ë ¤ì›€
3. í†µí•©í™˜ê²½ì˜ í•„ìš”ì„±

SPARK ì •ì˜

-  ê³ ì† ë²”ìš© ë¶„ì‚° ì»´í“¨íŒ… í”Œë«í¼

SPARK = HDFS + MapReduce ì²˜ë¦¬ ì—”ì§„



## SPARK í™˜ê²½ì˜ ì¥ì 

ì‚¬ìš©í¸ì˜ì„±

- ë§µë¦¬ë“€ìŠ¤ ëŒ€ë¹„ codeê°„ê²°
- Java, Scala, Python, R and SQL

í†µí•©í”Œë«í¼ ì œê³µ

- ìŠ¤íŒŒí¬ core, ìŠ¤íŒŒí¬ ìŠ¤íŠ¸ë¦¬ë°, ìŠ¤íŒŒí¬ ML, ìŠ¤íŒŒíŠ¸ SQL, ìŠ¤íŒŒí¬ GpaphX

ë¶„í•  ì²˜ë¦¬

RDD (Resilient Distributed Dataset) ğŸŒŸ

- íƒ„ë ¥ìˆëŠ” ë¶„í• ëœ ë°ì´í„°
- Mini batch RDD ì‚¬ìš©
- ìŠ¤íŒŒí¬ì˜ ê°€ì¥ í° ì¥ì 



## SPARKì˜ í•µì‹¬

SPARK / Hadoop êµ¬ì¡°

Simple Spark Structure

![image-20210806152612783](SPARK.assets/image-20210806152612783.png)



Simple Hadoop Structure

![What is the importance of Hadoop Architecture in Production Success?](https://lh3.googleusercontent.com/proxy/c0WUUl6h_dcRSct5R2pONkCHQUa8z88YwsE2Dh9F9ANTxMyWx3QPMVz9K4n3cWwG6rTg5RvZlsK6dGyGsrbu5-tjpmFQ3KTt1S3WBSzCxVbuovYw1vAMOAM)







## ìŠ¤íŒŒí¬ êµ¬ì„± ì»´í¬ë„ŒíŠ¸

spark Core

- spark jobê´€ë¦¬, ë‹¤ë¥¸ ì»´í¬ë„ŒíŠ¸ í•„ìš” ê¸°ëŠ¥ ì œê³µ

spark Streaming

- ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ì²˜ë¦¬
- Dstream (Discretized Stream) 
  - ì´ì‚° ìŠ¤íŠ¸ë¦¼ ê°œë…ì„ ì œì‹œí•˜ì—¬, ì‹œê°„ë³„ë¡œ ë„ì°©í•œ ë°ì´í„°ë“¤ì˜ ì—°ì†ì ì¸ ëª¨ì„. RDDì˜ ì—°ì†ì ì¸ ë¬¶ìŒì´ë¼ í•  ìˆ˜ ìˆë‹¤.

spark MLib

- ë¡œì§€ìŠ¤í‹± íšŒê·€, ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ë¶„ë¥˜, SVM, ì˜ì‚¬ ê²°ì • íŠ¸ë¦¬, Random Forests, ì„ í˜• íšŒê·€, K-Means Clustering ì œê³µ

spark SQL

- spark ì œê³µ SQL ì‚¬ìš©, hiveQLì—ì„œ ì œê³µí•˜ëŠ” SQL ì‚¬ìš©í•˜ì—¬ ëŒ€ê·œëª¨ ì •í˜• ë°ì´í„° ì²˜ë¦¬

spark GraphX

- Graph data ì—°ì‚° ì œê³µ





p61

```
val licLines = sc.textFile("/usr/local/spark/LICENSE")
val lineCnt = licLines.count()
```



p63

íŠ¹ì§•

ë¶ˆë³€ì„± ë³µì›ì„± íˆ¬ëª…ì„±



p64

RDDì—°ì‚°ì 

- ë³€í™˜ ì—°ì‚°ì
- í–‰ë™ ì—°ì‚°ì

p65

```
# val numbers = sc.parallelize(range(10, 51, 10))
val numbers = sc.parallelize(10 to 50 by 10)

# numbers.foreach(lambda x: print(x))
numbers.foreach(x => println(x))

# val numbersSquared = numbers.map(lambda num: num * num)
val numbersSquared = numbers.map(num => num * num)

# numbersSquared.foreach(lambda x: print(x))
numbersSquared.foreach(x => println(x))
```



p67

```
echo "15,16,20,20
77,80,94
94,98,16,31
31,15,20" > ~/client-ids.log
```



```
val lines = sc.textFile("/home/spark/client-ids.log")
val idsStr = lines.map(line => line.split(","))
idsStr.foreach(println(_))
idsStr.first()
idsStr.collect()
```



p71

sampleì€ ~ ì—°ì‚°ìë‹¤

sample

p72

takesample

p73

take

ì—°ì”ì : sampel, takesample, sample
